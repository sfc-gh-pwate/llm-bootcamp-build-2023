{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create --name llm-bootcamp -c https://repo.anaconda.com/pkgs/snowflake python=3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate llm-bootcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c https://repo.anaconda.com/pkgs/snowflake snowflake-snowpark-python pandas jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake_ml_python-1.0.12-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.model.models import llm\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "from snowflake.snowpark import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Secure Connection\n",
    "\n",
    "*NOTE: Update [connection.json](connection.json) and set your password, Hugging Face token, and replace '####' with your user number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Llama 2 from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = llm.LLMOptions(\n",
    "    token=connection_parameters['huggingface_token'],\n",
    "    max_batch_size=100,\n",
    ")\n",
    "llama_model = llm.LLM(\n",
    "    model_id_or_path=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register, Log and Deploy Llama 2 into Snowpark Container Services \n",
    "\n",
    "*NOTE: Logging and deploying the same model are one time operations. Once the model is logged and deployed, use ModeReference to get the reference to the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME    = 'LLAMA2_7b_CHAT'\n",
    "MODEL_VERSION = \"1.1\"\n",
    "MODEL_REGISTRY_DB = connection_parameters['database']\n",
    "MODEL_REGISTRY_SCHEMA = connection_parameters['schema']\n",
    "COMPUTE_POOL = connection_parameters['compute_pool']\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=MODEL_REGISTRY_DB, \n",
    "    schema_name=MODEL_REGISTRY_SCHEMA, \n",
    "    create_if_not_exists=True)\n",
    "\n",
    "llama_model_ref = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Deploying model for the first time can take ~25-30mins*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_ref.deploy(\n",
    "    deployment_name=\"llama_predict\", \n",
    "    platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    permanent=True, \n",
    "    options={\"compute_pool\": COMPUTE_POOL, \"num_gpus\": 1})\n",
    "\n",
    "llama_model_ref = model_registry.ModelReference(registry=registry,model_name=MODEL_NAME,model_version=MODEL_VERSION)\n",
    "llama_model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from JSON into Snowflake\n",
    "\n",
    "*NOTE: Reading data in JSON and storing it in a Snowflake table are one time operations. Once the data is loaded, use Snowpark to load the data from the existing table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/frosty_transcripts.json\",lines=True)\n",
    "sf_df = session.write_pandas(df,'frosty_transcripts',auto_create_table=True,quote_identifiers=False,overwrite=True)\n",
    "sf_df.show(max_width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompt Engineering Example\n",
    "\n",
    "For every transcript, define summarization instruction for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] Summarize this transcript in less than 200 words: \n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "df_inputs = sf_df.with_column('\"input\"',F.concat_ws(F.lit(\" \"),F.lit(begin_prompt),F.col('transcript'),F.lit(end_prompt))).select('\"input\"')\n",
    "df_inputs.show(max_width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using Simple Prompt\n",
    "\n",
    "Pass the summariation instruction to the LLM and examine results of 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_results = llama_model_ref.predict(deployment_name=\"llama_predict\",data=df_inputs)\n",
    "df_predict_results.select('\"input\"','\"generated_text\"').show(max_width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Prompt Engineering and Inference Example\n",
    "\n",
    "For every transcript, define more specific instruction for the LLM\n",
    "\n",
    "*NOTE: In the results, notice that the output is not consistent across all transcripts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = session.table('frosty_transcripts')\n",
    "\n",
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] Extract location and list of toys in JSON format: \n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "df_inputs = sf_df.with_column('\"input\"',F.concat_ws(F.lit(\" \"),F.lit(begin_prompt),F.col('transcript'),F.lit(end_prompt))).select('\"input\"')\n",
    "df_predict_results = llama_model_ref.predict(deployment_name=\"llama_predict\",data=df_inputs)\n",
    "df_predict_results.show(max_width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 2 Preparation\n",
    "\n",
    "Follow the instructions below to prepare your environment for BUILD LLM Bootcamp Day 2. \n",
    "\n",
    "*NOTE:* These operations can take about ~45-60mins depending on your wireless connection.\n",
    "\n",
    "1) Open terminal window and browse to the folder where you have cloned the repository\n",
    "2) Run command *`docker build --platform linux/amd64 -t llm-bootcamp .`*\n",
    "3) Once that image is built locally, run the following commands to push the image to Snowflake Registry\n",
    "    1) Replace YOUR_DB_NAME with the name of your DB and then run *`docker tag llm-bootcamp:latest sfsenorthamerica-build-spcs.registry.snowflakecomputing.com/YOUR_DB_NAME/schema_llm/image_repo/llm-bootcamp:latest`*\n",
    "    2) Run *`docker login sfsenorthamerica-build-spcs.registry.snowflakecomputing.com`* and login using your Snowflake LLM Bootcamp account username and password\n",
    "    3) Replace YOUR_DB_NAME with the name of your DB and then run *`docker push sfsenorthamerica-build-spcs.registry.snowflakecomputing.com/YOUR_DB_NAME/schema_llm/image_repo/llm-bootcamp:latest`*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
